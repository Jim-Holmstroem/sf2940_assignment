\documentclass[a4paper,twoside=false,abstract=false,numbers=noenddot,
titlepage=false,headings=small,parskip=half,version=last]{scrartcl}
\usepackage{lib/header}
\usepackage{lib/probability}
\begin{document}
\generateheader{Assignment 1}

\begin{exercise}{1: 1.12.3.10} {\bf Intersection of sigma algebras}   \\
    $\FF_1$ and $\FF_2$ are two sigma algebras of subsets of $\Omega$. Show
    that
    \begin{equation}
        \FF_1 \cap \FF_2
    \end{equation}
    is a sigma algebra of subsets of $\Omega$.
\end{exercise}
\begin{solution}
\end{solution}
\pagebreak

\begin{exercise}{2: 2.6.5.6} \textbf{Use Chen's Lemma} \\
    $X \in \distr{Po}{\lambda}$. Show that
    \begin{equation}
        \Expected[X^n] =
        \lambda \sum\limits_{k=0}^{n-1} \binom{n-1}{k}\Expected[X^k].
    \end{equation}
    \textit{Aid:} Use Chen's Lemma with suitable $H(x)$.
\end{exercise}
\begin{solution}
    \begin{lemma}
        \label{lemma:chen}  % TODO verify the correctness
        \textbf{Chen's Lemma} $X \in \distr{Po}{\lambda}$ and $H(x)$ is a bounded
        Borel function, then
        \begin{equation}
            \label{eq:chen}
            \Expected[XH(X)] = \lambda\Expected[H(X+1)].
        \end{equation}
    \end{lemma}
\end{solution}
\pagebreak

\begin{exercise}{3: 3.8.3.1}
    \textbf{Joint Distributions \& Conditional Expectations} \\
    Let $(X, Y)$ be a bivariate random variable, where $X$ is discrete and $Y$
    is continuous. $(X, Y)$ has a joint probability mass - and density function
    given by
    \begin{equation}
        f_{X,Y}(k, y) = \begin{cases}
            \partdev{P(X=k, Y\le y)}{y} =
            \lambda\frac{(\lambda y)^k}{k!}e^{-2\lambda y}
                    &,\, k\in\ZZ_{\ge 0},\, y\in [0, \infty) \\
            0       &.
        \end{cases}
    \end{equation}

    (a) Check that
    \begin{equation}
        \sum\limits_{k=0}^\infty \int\limits_0^\infty f_{X,Y}(k,y)dy =
        \int\limits_0^\infty \sum\limits_{k=0}^\infty f_{X,Y}(k,y)dy = 1
    \end{equation}

    (b) Compute the mixed moment $\Expected[XY]$ defined as
    \begin{equation}
        \Expected[XY] =
        \sum\limits_{k=0}^\infty \int\limits_0^\infty f_{X,Y}(k,y)dy.
    \end{equation}
    \Answer $\frac{2}{\lambda}$

    (c) Find the marginal p.m.f. of $X$.
    \Answer $X\in\distr{Ge}{1/2}$

    (d) Compute the marginal density of $Y$ here defined as
    \begin{equation}
        f_Y(y) = \begin{cases}
            \sum\limits_{k=0}^\infty f_{X,Y}(k,y) &, \, y\in[0,\infty) \\
             0                                    &.
        \end{cases}
    \end{equation}
    \Answer $Y\in\distr{Exp}{\frac{1}{\lambda}}$

    (e) Find
    \begin{equation}
        \gprob{\conditional{X}{Y}}{\conditional{k}{y}} =
        \Prob{\conditional{X=k}{Y=y}}, \, k\in\ZZ_{\ge 0}
    \end{equation}
    \Answer $\conditional{X}{Y} = y\in\distr{Po}{\lambda y}$.

    (f) Compute $\Expected[\conditional{X}{Y=y}]$ and then $\Expected[XY]$ using
    double expectation. Compare your results with (b).
\end{exercise}
\begin{solution}
\end{solution}
\pagebreak

\begin{exercise}{4: 3.8.3.14} \textbf{Computations on a distribution} \\
    Let $(X,Y)$ be a bivariate r.v. such that
    \begin{equation}
        \conditional{Y}{X=x} \in \distr{Fs}{x},\quad
        f_X(x)=3x^2,\quad
        x\in [0, 1].
    \end{equation}
    Compute $\Expected[Y]$, $\Variance[Y]$, $\CoVariance(X, Y)$ and the p.m.f.
    of $Y$.
    \Answer
    ${\Expected[Y]=\frac{3}{2}}$,
    ${\Variance[Y]=\frac{9}{4}}$,
    ${\CoVariance(X,Y)=-\frac{1}{8}}$, and
    $\gprob{Y}{k} = \frac{18}{(k+3)(k+2)(k+1)k},\, k \ge 1$.

\end{exercise}
\begin{solution}
\end{solution}
\pagebreak

\begin{exercise}{5: 4.7.2.4} Equidistribution \\
    Let $\left\{{X_k}\right\}_{k=1}^n$ be independent and identically
    distributed. Furthermore $\left\{{a_k}\right\}_{k=1}^n$, $a_k \in \RR$. Set
    \begin{equation}
        Y_1 = \sum\limits_k a_k X_k
    \end{equation}
    and
    \begin{equation}
        Y_2 = \sum\limits_k a_{n-k+1} X_k.
    \end{equation}
    Show that
    \begin{equation}
        Y_1 \Equidistributed Y_2.
    \end{equation}
\end{exercise}
\begin{solution}
\end{solution}
\pagebreak

\begin{exercise}{6: 5.8.3.11} \textbf{Laplace distribution} \\
    Let $\left\{{X_k}\right\}_{k=1}^n$ be independent and identically
    distributed with
    ${X_k \in\distr{$L$}{a},}\, {k\in[1,N_p],}\, {N_p\in \distr{Fs}{p}}$.
    $N_p$ is independent of the varibles $\left\{X_k\right\}$. We set
    \begin{equation}
        S_{N_p} = \sum\limits_{k=1}^{N_p}X_k.
    \end{equation}
    Show that $\sqrt{p}S_{N_p}\in\distr{$L$}{a}$.
\end{exercise}
\begin{solution}
\end{solution}
\pagebreak

\begin{exercise}{7: 7.6.1.1} \textbf{Mean square convergence}\\
    Assume $X_n, Y_n\in \distr{$L_2$}{\Omega,\FF,P}\, \forall n$ and
    \begin{equation}
        X_n \StackConverges{2} X, \quad
        Y_n \StackConverges{2} Y \quad
        \text{as}\quad n\rightarrow\infty
    \end{equation}
    Let $a, b \in \RR$. Show that
    \begin{equation}
        aX_n + bY_n\StackConverges{2} aX + bY\quad
        \text{as}\quad n\rightarrow\infty
    \end{equation}
    You should use the definition of mean square convergence and suitable
    properties of $\|X\|$ as defined in (LN 7.3).
\end{exercise}
\begin{solution}
\end{solution}
\pagebreak

%-----------------------
\end{document}
